# AI Governance 2026 (Governance-First)
## Frontier Awareness Without the Hype

## What this repository contains

This repository supports the two-volume book collection:

**AI Governance 2026 (Governance-First)**  
A frontier-focused continuation and capstone of the Governance-First AI series.

This collection builds on the foundational volumes:

• Governed Machine Learning  
• Governance AI for Accounting and Audit  
• Governance AI for Law Practice  
• Governance AI for Financial Advice  
• Governance AI for Investment Banking  
• Governance AI for Consulting  
• Governance-First Fine-Tuning for Financial Practitioners  

Those earlier books establish general governance principles and domain discipline.

This final collection focuses on something different:

**how AI implementation is evolving at the frontier — and how governance must evolve with it.**

These volumes examine recent developments emerging from leading conferences and applied research, translating them into institutional patterns suitable for real organizations.

The goal is not speculative futurism.

The goal is operational foresight.

This is not a showcase of model capability.

It is a study of governable capability.

Every output remains explicitly labeled: **Not verified.**


## Contents

### Books (PDF)

• Volume I — Foundations and Frontier Risks  
https://github.com/alexdibol/ai-governance_2026/blob/main/book/BOOK%20VOLUME%201.pdf  

• Volume II — Applied Governance in Frontier Domains  
https://github.com/alexdibol/ai-governance_2026/blob/main/book/BOOK%20VOLUME%202.pdf  


### Companion notebooks (Colab-ready)

• Notebooks folder  
https://github.com/alexdibol/ai-governance_2026/tree/main/notebooks  


### Direct Colab links (example)

• Chapter 1 Notebook  
https://colab.research.google.com/github/alexdibol/ai-governance_2026/blob/main/notebooks/CHAPTER_1.ipynb  

Each chapter in both volumes is accompanied by a corresponding Colab notebook.


## Who this is for

This collection is designed for:

• MBA and Master of Finance students  
• financial practitioners in high-accountability environments  
• risk, compliance, and governance teams  
• transformation and innovation leaders  
• instructors teaching applied AI responsibly  

No advanced ML engineering background is required.

The objective is not optimization.

The objective is institutional readiness.


## Core thesis: governance must scale with capability

Across all volumes in the Governance-First collection, one principle is non-negotiable:

Capability ↑ ⇒ Risk ↑ ⇒ Controls ↑

Frontier AI systems introduce new classes of risk:

• evaluation opacity  
• automation bias  
• tool-mediated action leakage  
• narrative hallucination  
• silent compounding of small errors  
• multimodal injection  
• decision laundering through fluent outputs  

These risks do not announce themselves.

They appear as confidence.

This collection trains a culture:

• evaluation before enthusiasm  
• evidence before deployment  
• controls before autonomy  
• accountability before scale  
• documentation before decisions  


## Companion notebooks: governed frontier laboratories

The notebooks are not tutorials.

They are governance laboratories.

Each notebook operationalizes one chapter concept and produces auditable artifacts intended to model institutional-grade AI experimentation.

Non-negotiables across all notebooks:

• synthetic data only  
• no autonomous decision authority  
• explicit scope boundaries  
• outputs labeled Not verified  
• human review required  
• reproducible runs where feasible  
• evidence-first evaluation  
• governance artifacts treated as first-class outputs  


## Standardized artifact bundle (every run)

Each execution generates a governed evidence package, including:

• run_manifest  
• schemas  
• validation logs  
• metrics with context and limitations  
• model or system card  
• boundary and refusal tests  
• risk log  
• governance memo  
• explicit declaration of non-decision authority  


## What makes this governance-first

Across both volumes, the framework enforces:

• separation of generation, verification, and approval  
• explicit institutional scope  
• refusal and boundary testing  
• uncertainty labeling  
• reproducibility requirements  
• audit-ready documentation  
• mandatory human accountability  

This prevents AI theater:
polished outputs without institutional defensibility.


## Important note

This repository and books are provided for educational and research purposes only.

They do not constitute:

• investment advice  
• legal advice  
• tax advice  
• compliance determinations  
• operational recommendations  

Human professional review is mandatory for any reliance-bearing use.

Confidential or proprietary information must never be provided to external systems.


## Use of generative AI tools (transparency statement)

Generative AI tools were used to assist with drafting, editing, formatting, and code scaffolding.

However:

• conceptual design  
• pedagogical structure  
• governance framework  
• risk taxonomy  
• artifact standards  
• boundary definitions  
• editorial judgment  
• final acceptance  

remained fully under human control.

The author assumes full responsibility for all content, structure, interpretation, and conclusions.


## Position within the Governance-First AI series

This two-volume collection serves as the frontier capstone to the Governance-First AI program, following:

• Governed Machine Learning  
• Governance AI for Accounting  
• Governance AI for Law  
• Governance AI for Financial Advice  
• Governance AI for Consulting  
• Governance AI for Investment Banking  
• Governance-First Fine-Tuning for Financial Practitioners  

These earlier volumes establish baseline discipline.

AI Governance 2026 extends that discipline into emerging capability domains.

The purpose is not to predict the future.

The purpose is to govern it.


## License

Released under the MIT License.
